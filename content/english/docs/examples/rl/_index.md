---
title: Reinforcement Learning
toc: false
weight: 7
---

| Starter | Keras Version                                                                                                        | Title                                                                                            | Date Created | Last Modified |
| ------- | -------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------ | ------------ | ------------- |
|         | {{< hextra/hero-button text="V3" style="background: rgb(23, 132, 133);pointer-events: none; padding: 0.1em 1em;" >}} | [Actor Critic Method]({{< relref "/docs/examples/rl/actor_critic_cartpole" >}})                  | 2020/05/13   | 2024/02/22    |
|         | {{< hextra/hero-button text="V3" style="background: rgb(23, 132, 133);pointer-events: none; padding: 0.1em 1em;" >}} | [Proximal Policy Optimization]({{< relref "/docs/examples/rl/ppo_cartpole" >}})                  | 2021/06/24   | 2024/03/12    |
|         | {{< hextra/hero-button text="V3" style="background: rgb(23, 132, 133);pointer-events: none; padding: 0.1em 1em;" >}} | [Deep Q-Learning for Atari Breakout]({{< relref "/docs/examples/rl/deep_q_network_breakout" >}}) | 2020/05/23   | 2024/03/16    |
|         | {{< hextra/hero-button text="V3" style="background: rgb(23, 132, 133);pointer-events: none; padding: 0.1em 1em;" >}} | [Deep Deterministic Policy Gradient (DDPG)]({{< relref "/docs/examples/rl/ddpg_pendulum" >}})    | 2020/06/04   | 2024/03/23    |

| Starter | Keras Version                                                                                                        | Title                                                                                            | Date Created | Last Modified â–¼ |
| ------- | -------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------ | ------------ | --------------- |
|         | {{< hextra/hero-button text="V3" style="background: rgb(23, 132, 133);pointer-events: none; padding: 0.1em 1em;" >}} | [Deep Deterministic Policy Gradient (DDPG)]({{< relref "/docs/examples/rl/ddpg_pendulum" >}})    | 2020/06/04   | 2024/03/23      |
|         | {{< hextra/hero-button text="V3" style="background: rgb(23, 132, 133);pointer-events: none; padding: 0.1em 1em;" >}} | [Deep Q-Learning for Atari Breakout]({{< relref "/docs/examples/rl/deep_q_network_breakout" >}}) | 2020/05/23   | 2024/03/16      |
|         | {{< hextra/hero-button text="V3" style="background: rgb(23, 132, 133);pointer-events: none; padding: 0.1em 1em;" >}} | [Proximal Policy Optimization]({{< relref "/docs/examples/rl/ppo_cartpole" >}})                  | 2021/06/24   | 2024/03/12      |
|         | {{< hextra/hero-button text="V3" style="background: rgb(23, 132, 133);pointer-events: none; padding: 0.1em 1em;" >}} | [Actor Critic Method]({{< relref "/docs/examples/rl/actor_critic_cartpole" >}})                  | 2020/05/13   | 2024/02/22      |
